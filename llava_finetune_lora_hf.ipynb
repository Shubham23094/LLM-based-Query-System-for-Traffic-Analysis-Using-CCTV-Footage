{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshashank23088\u001b[0m (\u001b[33mshashankgsharma\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/shashank23088/.netrc\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "import av\n",
    "import gc\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "\n",
    "import torch\n",
    "import datasets\n",
    "from trl import SFTTrainer\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoProcessor, LlavaOnevisionForConditionalGeneration, BitsAndBytesConfig, set_seed, TrainingArguments, EvalPrediction\n",
    "\n",
    "\n",
    "import wandb\n",
    "wandb.login(key='cefd9d24e53c2aa0dc75b785b40045c6e6badced')\n",
    "# wandb.init(project=\"accident_detection\")\n",
    "\n",
    "from huggingface_hub import login\n",
    "login('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')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "# torch.set_default_device(\"cuda\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input paths\n",
    "train_accident_dir = \"../data/train/accident\"\n",
    "train_non_accident_dir = \"../data/train/non_accident\"\n",
    "test_accident_dir = \"../data/test/accident\"\n",
    "test_non_accident_dir = \"../data/test/non_accident\"\n",
    "\n",
    "train_accident_json = \"../data/accident_vehicle_count_YOLO_train.json\"\n",
    "train_non_accident_json = \"../data/non_accident_vehicle_count_YOLO_train.json\"\n",
    "test_accident_json = \"../data/accident_vehicle_count_YOLO_test.json\"\n",
    "test_non_accident_json = \"../data/non_accident_vehicle_count_YOLO_test.json\"\n",
    "\n",
    "# Output paths\n",
    "train_output_json = \"../data/prepared_train_data.json\"\n",
    "test_output_json = \"../data/prepared_test_data.json\"\n",
    "\n",
    "repo_name = \"shashank23088/llava-onevision-qwen2-7b-traffic\"\n",
    "model_name = \"llava-hf/llava-onevision-qwen2-7b-ov-hf\"\n",
    "\n",
    "# Load the JSON files\n",
    "def load_json(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accident_data = load_json(train_accident_json)\n",
    "train_non_accident_data = load_json(train_non_accident_json)\n",
    "test_accident_data = load_json(test_accident_json)\n",
    "test_non_accident_data = load_json(test_non_accident_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'car': 6, 'truck': 1, 'bike': 0, 'bicycle': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accident_data['1u69z-wsDIc_000181']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'car': 12, 'truck': 3, 'bike': 0, 'bicycle': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_non_accident_data['201804191441002645']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to prepare data\n",
    "def prepare_data(data, folder, accident_label):\n",
    "    prepared = []\n",
    "    for video_id, vehicles in data.items():\n",
    "        # Construct the path to frames\n",
    "        video_folder = os.path.join(folder, video_id, \"images\")\n",
    "        if not os.path.exists(video_folder):\n",
    "            video_folder = os.path.join(folder, video_id)  # Fallback if no \"images\" subfolder\n",
    "        if not os.path.exists(video_folder):  # Skip if folder doesn't exist\n",
    "            print(f\"Warning: Missing folder for video_id {video_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Get all frames\n",
    "        frames = [\n",
    "            os.path.join(video_folder, frame)\n",
    "            for frame in os.listdir(video_folder) if frame.endswith(\".jpg\")\n",
    "        ]\n",
    "        \n",
    "        # Sort frames for consistency\n",
    "        frames.sort()\n",
    "        \n",
    "        # Skip if no frames are found\n",
    "        if not frames:\n",
    "            print(f\"Warning: No frames found in folder for video_id {video_id}\")\n",
    "            continue\n",
    "\n",
    "        # Add congestion_level as placeholder (since it's not available in your data)\n",
    "        prepared.append({\n",
    "            \"video_id\": video_id,\n",
    "            \"frames\": frames,\n",
    "            \"labels\": {\n",
    "                \"vehicles\": vehicles,\n",
    "                \"congestion_level\": \"unknown\",  # Placeholder\n",
    "                \"accident\": accident_label\n",
    "            }\n",
    "        })\n",
    "    return prepared\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No frames found in folder for video_id 0RJPQ_97dcs_004153\n",
      "Warning: No frames found in folder for video_id 0RJPQ_97dcs_004033\n",
      "Warning: No frames found in folder for video_id 0RJPQ_97dcs_003107\n"
     ]
    }
   ],
   "source": [
    "# Prepare train data\n",
    "train_accident_prepared = prepare_data(train_accident_data, train_accident_dir, \"yes\")\n",
    "train_non_accident_prepared = prepare_data(train_non_accident_data, train_non_accident_dir, \"no\")\n",
    "train_final_data = train_accident_prepared + train_non_accident_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared train data saved to ../data/prepared_train_data.json\n"
     ]
    }
   ],
   "source": [
    "# Save train data\n",
    "with open(train_output_json, \"w\") as f:\n",
    "    json.dump(train_final_data, f, indent=4)\n",
    "print(f\"Prepared train data saved to {train_output_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "test_accident_prepared = prepare_data(test_accident_data, test_accident_dir, \"yes\")\n",
    "test_non_accident_prepared = prepare_data(test_non_accident_data, test_non_accident_dir, \"no\")\n",
    "test_final_data = test_accident_prepared + test_non_accident_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared test data saved to ../data/prepared_test_data.json\n"
     ]
    }
   ],
   "source": [
    "# Save test data\n",
    "with open(test_output_json, \"w\") as f:\n",
    "    json.dump(test_final_data, f, indent=4)\n",
    "print(f\"Prepared test data saved to {test_output_json}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA LOADING AND PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test datasets\n",
    "def load_data(train_json_path, test_json_path):\n",
    "    with open(train_json_path, \"r\") as f:\n",
    "        train_data = json.load(f)\n",
    "    with open(test_json_path, \"r\") as f:\n",
    "        test_data = json.load(f)\n",
    "    \n",
    "    # Convert to Dataset objects\n",
    "    return DatasetDict({\n",
    "        \"train\": datasets.Dataset.from_list(train_data),\n",
    "        \"test\": datasets.Dataset.from_list(test_data)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['video_id', 'frames', 'labels'],\n",
      "        num_rows: 197\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['video_id', 'frames', 'labels'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "dataset = load_data(train_output_json, test_output_json)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 6, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 2, 'bike': 0, 'car': 1, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 10, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 1, 'truck': 0}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 1, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 6, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 14, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 4, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 8, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 11, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 3, 'truck': 0}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 6, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 8, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 6, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 2, 'bike': 0, 'car': 6, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 1, 'truck': 0}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 1, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 15, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 5, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 7, 'truck': 6}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 5, 'truck': 0}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 8, 'truck': 0}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 3, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 10, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 5, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 2, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 1, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 7, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 5, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 7, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 4, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 7, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 8, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 6, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 6, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 3, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 5, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 16, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 7, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 2, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 4, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 5, 'truck': 5}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 2, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 11, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 2, 'truck': 0}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 9, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 11, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 4, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 13, 'truck': 4}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 5, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 3, 'bike': 0, 'car': 5, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 8, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 7, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 14, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 9, 'truck': 0}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 20, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 5, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 7, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 16, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 10, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 1, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 2, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 9, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 10, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 12, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 4, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 14, 'truck': 4}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 2, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 2, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 6, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 4, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 4, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 4, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 11, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 0, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 7, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 6, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 12, 'truck': 4}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 1, 'truck': 0}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 6, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 4, 'truck': 5}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 7, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 7, 'truck': 0}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 15, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 5, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 6, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 8, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 8, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 8, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 10, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 4, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 6, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 7, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 8, 'truck': 2}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 12, 'truck': 3}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 8, 'truck': 1}},\n",
       " {'accident': 'yes',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 6, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 13, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 3, 'bike': 0, 'car': 11, 'truck': 5}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 10, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 21, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 13, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 11, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 20, 'truck': 5}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 15, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 23, 'truck': 4}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 13, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 18, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 12, 'truck': 4}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 13, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 10, 'truck': 0}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 4, 'bike': 0, 'car': 5, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 14, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 10, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 16, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 19, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 3, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 18, 'truck': 4}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 9, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 6, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 17, 'truck': 4}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 21, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 13, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 13, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 15, 'truck': 4}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 11, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 12, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 9, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 15, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 11, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 15, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 16, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 11, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 18, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 18, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 2, 'bike': 0, 'car': 12, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 2, 'bike': 0, 'car': 9, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 21, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 15, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 15, 'truck': 4}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 15, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 12, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 16, 'truck': 4}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 13, 'truck': 0}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 17, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 14, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 3, 'bike': 0, 'car': 15, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 11, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 17, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 2, 'bike': 0, 'car': 19, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 19, 'truck': 5}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 12, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 3, 'bike': 0, 'car': 12, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 17, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 9, 'truck': 4}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 18, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 7, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 16, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 2, 'bike': 0, 'car': 2, 'truck': 0}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 2, 'bike': 0, 'car': 18, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 16, 'truck': 5}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 11, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 21, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 11, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 2, 'bike': 0, 'car': 12, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 16, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 8, 'truck': 0}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 15, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 10, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 4, 'truck': 0}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 10, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 3, 'bike': 0, 'car': 13, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 16, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 9, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 21, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 12, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 11, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 20, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 21, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 8, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 12, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 19, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 20, 'truck': 0}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 3, 'bike': 0, 'car': 11, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 16, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 19, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 3, 'bike': 0, 'car': 11, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 15, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 13, 'truck': 2}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 5, 'truck': 4}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 22, 'truck': 3}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 4, 'bike': 0, 'car': 8, 'truck': 0}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 23, 'truck': 4}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 7, 'truck': 1}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 16, 'truck': 0}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 0, 'bike': 0, 'car': 14, 'truck': 5}},\n",
       " {'accident': 'no',\n",
       "  'congestion_level': 'unknown',\n",
       "  'vehicles': {'bicycle': 1, 'bike': 0, 'car': 4, 'truck': 0}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset, processor, fixed_frames=8, frame_interval=16, frame_resolution=(112, 112)):\n",
    "    def process_example(example):\n",
    "        # Select a fixed number of frames evenly from the start and end\n",
    "        def select_fixed_frames(frames, fixed_frames, interval, resolution):\n",
    "            num_frames = len(frames)\n",
    "            half_frames = fixed_frames // 2\n",
    "\n",
    "            # Select frames from the start and end with the given interval\n",
    "            start_frames = frames[::interval][:half_frames]\n",
    "            end_frames = frames[-1::-interval][:half_frames][::-1]  # Reverse end frames for proper order\n",
    "\n",
    "            selected_frames = start_frames + end_frames\n",
    "\n",
    "            # If fewer frames than needed, pad by repeating frames\n",
    "            while len(selected_frames) < fixed_frames:\n",
    "                selected_frames.append(selected_frames[-1])\n",
    "\n",
    "            selected_frames = selected_frames[:fixed_frames]  # Ensure exact number of frames\n",
    "            processed_frames = [\n",
    "                np.array(Image.open(frame).convert(\"RGB\").resize(resolution))\n",
    "                for frame in selected_frames\n",
    "            ]\n",
    "            return np.stack(processed_frames)\n",
    "\n",
    "        # Process frames\n",
    "        frames = select_fixed_frames(\n",
    "            example[\"frames\"], fixed_frames, frame_interval, frame_resolution\n",
    "        )\n",
    "\n",
    "        # Prepare the label text\n",
    "        label_text = str({\n",
    "            \"vehicles\": example[\"labels\"][\"vehicles\"],\n",
    "            \"congestion_level\": example[\"labels\"][\"congestion_level\"],\n",
    "            \"accident\": example[\"labels\"][\"accident\"]\n",
    "        })\n",
    "\n",
    "        # Include the expected response directly in the input prompt\n",
    "        # input_text = (\n",
    "        #     \"<|im_start|>user <video>\\nGenerate Traffic Report<|im_end|>\"\n",
    "        #     f\"<|im_start|>assistant\\n{label_text}\"\n",
    "        # )\n",
    "\n",
    "        conversation = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"video\"},\n",
    "                    {\"type\": \"text\", \"text\": \"\"\"\n",
    "                        Generate a detailed report in JSON format on the traffic statistics in this video:\n",
    "                        {\n",
    "                            vehicles: {\n",
    "                                'car': <count>,\n",
    "                                'truck': <count>,\n",
    "                                'bike': <count>,\n",
    "                                'bicycle': <count>\n",
    "                            },\n",
    "                            congestion_level: '<low|medium|high>',\n",
    "                            accident: '<yes|no>'\n",
    "                        }\n",
    "                    \"\"\"},\n",
    "                ],\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        input_text = processor.apply_chat_template(conversation, add_generation_prompt=False)\n",
    "        input_text += label_text\n",
    "\n",
    "        # Tokenize inputs (video frames + text)\n",
    "        input_encoding = processor(\n",
    "            text=input_text,\n",
    "            videos=frames,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "            # truncation=True,  # Dynamically truncate if needed\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_encoding[\"input_ids\"][0],\n",
    "            \"attention_mask\": input_encoding[\"attention_mask\"][0],\n",
    "        }\n",
    "\n",
    "    # Map the dataset with the processed examples\n",
    "    processed_dataset = dataset.map(\n",
    "        lambda x: process_example(x),\n",
    "        batched=False,\n",
    "        remove_columns=dataset.column_names,\n",
    "    )\n",
    "    return processed_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINETUNING WITH SFT AND QLORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processor\n",
    "processor = AutoProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle and select a small sample\n",
    "# sample_train = dataset[\"train\"].shuffle(seed=42).select(range(10))\n",
    "# sample_test = dataset[\"test\"].shuffle(seed=42).select(range(10))\n",
    "\n",
    "# # Preprocess the sample datasets\n",
    "# sample_train_processed = preprocess_dataset(sample_train, processor)\n",
    "# sample_test_processed = preprocess_dataset(sample_test, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_train_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sample_train_processed['labels'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sample_train_processed['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sample_train_processed['input_ids'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18d1fdd76f145f1900d582afda35bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/197 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4395e6e407cb48d28d8bc3796814c4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"train\"] = preprocess_dataset(dataset[\"train\"], processor)\n",
    "dataset[\"test\"] = preprocess_dataset(dataset[\"test\"], processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 197\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a3803c02654612884ea5bc0a211ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ac3e2cf4e2488892904c36aca1609d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9321bb3bdf4d5aa92af7dbe772760b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4e8defe95f486b8ea04ff616c14146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/shashank23088/processed-traffic-data/commit/db65e7dbeb178f22b03823bf31110c2f79d6511a', commit_message='Upload dataset', commit_description='', oid='db65e7dbeb178f22b03823bf31110c2f79d6511a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/shashank23088/processed-traffic-data', endpoint='https://huggingface.co', repo_type='dataset', repo_id='shashank23088/processed-traffic-data'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"shashank23088/processed-traffic-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINETUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 197\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"shashank23088/processed-traffic-data\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle and split the train dataset (80% train, 20% eval)\n",
    "# split_dataset = dataset['train'].train_test_split(test_size=0.2, seed=42)  # 20% for eval\n",
    "\n",
    "# # Now you have train and eval datasets in the train_dataset object\n",
    "# train_dataset = split_dataset['train']  # The training part\n",
    "# eval_dataset = split_dataset['test']   # The eval part (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ef5cf206ed4a45a319663f2c2f3b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configure 4-bit quantization\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# Load the model with 4-bit quantization\n",
    "model = LlavaOnevisionForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=\"all-linear\",\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 51425280 || all params: 4613178912 || trainable%: 1.1147471403337585\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Define the training arguments with memory optimizations\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llava_finetuned\",\n",
    "    per_device_train_batch_size=1,  # Reduce batch size\n",
    "    gradient_accumulation_steps=16,  # Accumulate gradients over more steps\n",
    "    num_train_epochs=5,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,  # Use mixed precision training\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_num_workers=4,  # Adjust workers to prevent overload\n",
    "    report_to=\"wandb\",\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=repo_name,\n",
    "    # load_best_model_at_end=True,\n",
    "    # metric_for_best_model=\"accident_accuracy\",\n",
    "    # greater_is_better=True,\n",
    "    dataloader_pin_memory=True,  # Pin memory for faster data loading\n",
    "    warmup_steps=100,  # Gradual warm-up of learning rate\n",
    ")\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],  # Pass the train dataset\n",
    "    # eval_dataset=eval_dataset,  # Pass the eval dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./llava_finetuned\",  # Output directory for model and checkpoints\n",
    "#     per_device_train_batch_size=1,  # Batch size for training\n",
    "#     gradient_accumulation_steps=8,  # Accumulate gradients over 8 steps to simulate a larger batch\n",
    "#     num_train_epochs=3,  # Number of epochs\n",
    "#     # max_steps=200,  # Optionally, you can set max steps instead of num_train_epochs\n",
    "#     evaluation_strategy=\"no\",  # Disable evaluation\n",
    "#     save_strategy=\"no\",  # Disable model saving during training\n",
    "#     logging_steps=10,  # Log every 10 steps\n",
    "#     learning_rate=2e-4,  # Learning rate for training\n",
    "#     fp16=True,  # Use mixed precision training to reduce memory usage\n",
    "#     save_total_limit=2,  # Limit the number of saved checkpoints\n",
    "#     remove_unused_columns=False,  # Ensure unused columns are removed from dataset\n",
    "#     dataloader_num_workers=2,  # Number of workers for loading data\n",
    "#     report_to=\"wandb\",  # Log metrics to W&B (optional)\n",
    "#     push_to_hub=True,  # Optionally, push model to Hugging Face Hub\n",
    "#     hub_model_id=repo_name,  # Hugging Face model ID\n",
    "# )\n",
    "\n",
    "# # Initialize the trainer without evaluation\n",
    "# trainer = SFTTrainer(\n",
    "#     model=model,\n",
    "#     tokenizer=processor.tokenizer,\n",
    "#     args=training_args,\n",
    "#     train_dataset=dataset['train'],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f953a04681bf473f987bbba43730137e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112244406508074, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/shashank23088/Documents/shashank/LLMFinetune/wandb/run-20241119_022911-vwuym4t4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shashankgsharma/huggingface/runs/vwuym4t4' target=\"_blank\">./llava_finetuned</a></strong> to <a href='https://wandb.ai/shashankgsharma/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shashankgsharma/huggingface' target=\"_blank\">https://wandb.ai/shashankgsharma/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shashankgsharma/huggingface/runs/vwuym4t4' target=\"_blank\">https://wandb.ai/shashankgsharma/huggingface/runs/vwuym4t4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 11:14, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11.277100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>10.501400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>10.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>10.487400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>11.239200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>10.423200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=60, training_loss=10.737729136149088, metrics={'train_runtime': 689.1833, 'train_samples_per_second': 1.429, 'train_steps_per_second': 0.087, 'total_flos': 7.014390786542995e+16, 'train_loss': 10.737729136149088, 'epoch': 4.649746192893401})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./llava_finetuned_model/processor_config.json']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and processor\n",
    "trainer.save_model(\"./llava_finetuned_model\")\n",
    "processor.save_pretrained(\"./llava_finetuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90ae16f99d74078ae0e11755d719fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/shashank23088/llava-onevision-qwen2-7b-traffic/commit/3cbf5a27b44855114e55c21f5db893c9583fd44f', commit_message='Upload processor', commit_description='', oid='3cbf5a27b44855114e55c21f5db893c9583fd44f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/shashank23088/llava-onevision-qwen2-7b-traffic', endpoint='https://huggingface.co', repo_type='model', repo_id='shashank23088/llava-onevision-qwen2-7b-traffic'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push the model to the Hugging Face Hub\n",
    "model.push_to_hub(repo_name)\n",
    "processor.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the adapters with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the base model\n",
    "base_model = LlavaOnevisionForConditionalGeneration.from_pretrained(\n",
    "    \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load the adapters directly from the Hugging Face Hub\n",
    "adapter_model_path = \"shashank23088/llava-onevision-qwen2-7b-traffic\"\n",
    "model_with_adapters = PeftModel.from_pretrained(base_model, adapter_model_path)\n",
    "\n",
    "# Merge the adapters with the base model\n",
    "merged_model = model_with_adapters.merge_and_unload()\n",
    "\n",
    "print(\"Adapters successfully merged with the base model.\")\n",
    "\n",
    "# Save the fully merged model\n",
    "merged_model.save_pretrained(\"./llava_finetuned_model_merged\")\n",
    "\n",
    "# Save the processor associated with the base model\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-onevision-qwen2-7b-ov-hf\")\n",
    "processor.save_pretrained(\"./llava_finetuned_model_merged\")\n",
    "print(\"Merged model and processor saved to ./llava_finetuned_model_merged\")\n",
    "\n",
    "# Push the merged model and processor to the Hugging Face Hub\n",
    "merge_repo_name = \"shashank23088/llava-traffic-finetuned-merged\" \n",
    "merged_model.push_to_hub(merge_repo_name)\n",
    "processor.push_to_hub(merge_repo_name)\n",
    "\n",
    "print(f\"Merged model pushed to Hugging Face Hub: https://huggingface.co/{merge_repo_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddbb6511e1b4d4f903fa45e4661e8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "model = LlavaOnevisionForConditionalGeneration.from_pretrained(f'{repo_name}-merged', quantization_config=quantization_config, device_map='auto')\n",
    "processor = AutoProcessor.from_pretrained(f'{repo_name}-merged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video_pyav(container, indices):\n",
    "    '''\n",
    "    Decode the video with PyAV decoder.\n",
    "    Args:\n",
    "        container (`av.container.input.InputContainer`): PyAV container.\n",
    "        indices (`List[int]`): List of frame indices to decode.\n",
    "    Returns:\n",
    "        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n",
    "    '''\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "# Load the video as an np.array, sampling uniformly 8 frames (can sample more for longer videos, up to 32 frames)\n",
    "# video_path = hf_hub_download(repo_id=\"raushan-testing-hf/videos-test\", filename=\"sample_demo_1.mp4\", repo_type=\"dataset\")\n",
    "container = av.open('../data/video.mp4')\n",
    "total_frames = container.streams.video[0].frames\n",
    "indices = np.arange(0, total_frames, total_frames / 8).astype(int)\n",
    "video = read_video_pyav(container, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user \\n\\n                Generate a detailed report in JSON format on the traffic statistics in this video:\\n                {\\n                    vehicles: {\\n                        \\'car\\': <count>,\\n                        \\'truck\\': <count>,\\n                        \\'bike\\': <count>,\\n                        \\'bicycle\\': <count>\\n                    },\\n                    congestion_level: \\'<low|medium|high>\\',\\n                    accident: \\'<yes|no>\\'\\n                }\\n            assistant\\n```json\\n{\\n  \"vehicles\": {\\n    \"car\": 10,\\n    \"truck\": 2,\\n    \"bike\": 0,\\n    \"bicycle\": 0\\n  },\\n  \"congestion_level\": \"low\",\\n  \"accident\": \"no\"\\n}\\n```']\n"
     ]
    }
   ],
   "source": [
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"video\"},\n",
    "            {\"type\": \"text\", \"text\": \"\"\"\n",
    "                Generate a detailed report in JSON format on the traffic statistics in this video:\n",
    "                {\n",
    "                    vehicles: {\n",
    "                        'car': <count>,\n",
    "                        'truck': <count>,\n",
    "                        'bike': <count>,\n",
    "                        'bicycle': <count>\n",
    "                    },\n",
    "                    congestion_level: '<low|medium|high>',\n",
    "                    accident: '<yes|no>'\n",
    "                }\n",
    "            \"\"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "inputs = processor(videos=list(video), text=prompt, return_tensors=\"pt\").to(\"cuda:0\", torch.float16)\n",
    "\n",
    "out = model.generate(**inputs, max_new_tokens=300)\n",
    "result = processor.batch_decode(out, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vehicles': {'car': 10, 'truck': 2, 'bike': 0, 'bicycle': 0},\n",
       " 'congestion_level': 'low',\n",
       " 'accident': 'no'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(''.join(''.join(result[0].split('assistant')[1].strip('\\n').strip('```').strip('json').split('\\n')).split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../data/test/'\n",
    "output_dir = '../data/responses_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_frames_from_folder(folder_path, frame_paths, step=8):\n",
    "    \"\"\"\n",
    "    Reads every `step` frames from the given paths and stacks them into a numpy array.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): The base path of the folder (not used in this case).\n",
    "        frame_paths (list): List of paths to the individual frames (images).\n",
    "        step (int): Step size to sample frames. Default is 8.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Stacked sampled frames as a numpy array of shape (num_sampled_frames, height, width, 3).\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for i, frame_path in enumerate(frame_paths):\n",
    "        if i % step == 0:  # Sample every `step` frame\n",
    "            frame = Image.open(frame_path)\n",
    "            frames.append(np.array(frame.convert('RGB')))\n",
    "    return np.stack(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(frame_paths, video_id, processor, model, prompt, output_dir):\n",
    "    \"\"\"\n",
    "    Perform inference on a single video and parse the generated output using regex.\n",
    "    \n",
    "    Args:\n",
    "        frame_paths (list): List of paths to the frames (images) for the video.\n",
    "        video_id (str): Unique identifier for the video.\n",
    "        processor: Processor for converting frames and text prompt to tensors.\n",
    "        model: The model used for inference.\n",
    "        prompt (str): The text prompt to send with the video.\n",
    "        output_dir (str): Directory to save the generated JSON file.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Parsed JSON output from the model containing traffic statistics, or None if processing failed.\n",
    "    \"\"\"\n",
    "    # Sample every 8th frame for inference\n",
    "    sampled_frames = read_frames_from_folder(None, frame_paths, step=8)\n",
    "\n",
    "    # Prepare the inputs for the model\n",
    "    inputs = processor(videos=sampled_frames, text=prompt, return_tensors=\"pt\").to(\"cuda:0\", torch.float16)\n",
    "\n",
    "    # Perform inference (generation)\n",
    "    try:\n",
    "        out = model.generate(**inputs, max_new_tokens=300)\n",
    "        result = processor.batch_decode(out, skip_special_tokens=True, clean_up_tokenization_spaces=True)[0]\n",
    "        \n",
    "        # Apply regex to extract the JSON part from the model output\n",
    "        json_str = ''.join(''.join(result.split('assistant')[1].strip('\\n').strip('```').strip('json').split('\\n')).split(' '))\n",
    "        json_data = json.loads(json_str.replace(\"'\", \"\\\"\"))  # Fix single quotes to double quotes\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing result for video {video_id}. Raw output: {result}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        return None\n",
    "\n",
    "    # Save the output to a JSON file\n",
    "    output_file = os.path.join(output_dir, f'{video_id}.json')\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(json_data, f, indent=4)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalDataset(dataset, processor, model, output_dir, prompt):\n",
    "    \"\"\"\n",
    "    Evaluate the dataset by performing inference on each video and calculating evaluation metrics.\n",
    "    \n",
    "    Args:\n",
    "        dataset: The dataset to evaluate (with frames and labels).\n",
    "        processor: Processor for converting frames and text prompt to tensors.\n",
    "        model: The model used for inference.\n",
    "        output_dir (str): Directory to save the generated JSON files.\n",
    "        prompt (str): The text prompt to send with the video.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Accuracy for accident detection, MAE scores for vehicle counts.\n",
    "    \"\"\"\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    # Initialize vehicle count data for MAE calculation\n",
    "    vehicle_counts_true = {'car': [], 'truck': [], 'bike': [], 'bicycle': []}\n",
    "    vehicle_counts_pred = {'car': [], 'truck': [], 'bike': [], 'bicycle': []}\n",
    "\n",
    "    # Iterate through the dataset\n",
    "    for idx, row in enumerate(tqdm(dataset, desc=\"Evaluating dataset\")):\n",
    "        video_id = row['video_id']\n",
    "        frames = row['frames']  # Frames should be a list of paths\n",
    "        labels = row['labels']\n",
    "        \n",
    "        # Extract the true labels\n",
    "        true_accident = 1 if labels['accident'].lower() == 'yes' else 0\n",
    "        true_vehicle_counts = labels['vehicles']\n",
    "        \n",
    "        # Perform inference to get the predicted data\n",
    "        json_data = infer(frames, video_id, processor, model, prompt, output_dir)\n",
    "        \n",
    "        if json_data is None:\n",
    "            continue  # Skip this video if inference failed\n",
    "        \n",
    "        # Get predicted values for accident and vehicles\n",
    "        predicted_accident = 1 if json_data[\"accident\"].lower() == 'yes' else 0\n",
    "        predicted_vehicle_counts = json_data[\"vehicles\"]\n",
    "        \n",
    "        # Store the results for evaluation\n",
    "        true_labels.append(true_accident)\n",
    "        predicted_labels.append(predicted_accident)\n",
    "\n",
    "        for vehicle_type in ['car', 'truck', 'bike', 'bicycle']:\n",
    "            vehicle_counts_true[vehicle_type].append(true_vehicle_counts.get(vehicle_type, 0))\n",
    "            vehicle_counts_pred[vehicle_type].append(predicted_vehicle_counts.get(vehicle_type, 0))\n",
    "\n",
    "    # Calculate accuracy for accident detection\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Calculate MAE for vehicle counts\n",
    "    mae_scores = {}\n",
    "    for vehicle_type in ['car', 'truck', 'bike', 'bicycle']:\n",
    "        mae_scores[vehicle_type] = mean_absolute_error(vehicle_counts_true[vehicle_type], vehicle_counts_pred[vehicle_type])\n",
    "\n",
    "    # Print and return the evaluation results\n",
    "    print(f\"Accuracy for Accident Detection: {accuracy}\")\n",
    "    for vehicle_type, mae in mae_scores.items():\n",
    "        print(f\"MAE for {vehicle_type} count: {mae}\")\n",
    "    \n",
    "    return accuracy, mae_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"video\"},\n",
    "            {\"type\": \"text\", \"text\": \"\"\"\n",
    "                Generate a detailed report in JSON format on the traffic statistics in this video:\n",
    "                {\n",
    "                    vehicles: {\n",
    "                        'car': <count>,\n",
    "                        'truck': <count>,\n",
    "                        'bike': <count>,\n",
    "                        'bicycle': <count>\n",
    "                    },\n",
    "                    congestion_level: '<low|medium|high>',\n",
    "                    accident: '<yes|no>'\n",
    "                }\n",
    "            \"\"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f639fbf627472aa0e387a8e00031c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating dataset:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Accident Detection: 0.8\n",
      "MAE for car count: 2.68\n",
      "MAE for truck count: 0.72\n",
      "MAE for bike count: 0.7\n",
      "MAE for bicycle count: 0.55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8,\n",
       " {'car': np.float64(2.68),\n",
       "  'truck': np.float64(0.72),\n",
       "  'bike': np.float64(0.7),\n",
       "  'bicycle': np.float64(0.55)})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalDataset(dataset=dataset['test'], processor=processor, model=model, output_dir=output_dir, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
