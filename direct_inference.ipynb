{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:30:06.263243Z","iopub.status.busy":"2024-09-29T18:30:06.262597Z","iopub.status.idle":"2024-09-29T18:30:47.196178Z","shell.execute_reply":"2024-09-29T18:30:47.195022Z","shell.execute_reply.started":"2024-09-29T18:30:06.263199Z"},"trusted":true,"id":"FlAbFzhxD236"},"outputs":[],"source":["!pip install av --quiet\n","!pip install -U transformers --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-29T18:30:47.198682Z","iopub.status.busy":"2024-09-29T18:30:47.198361Z","iopub.status.idle":"2024-09-29T18:31:15.945557Z","shell.execute_reply":"2024-09-29T18:31:15.944724Z","shell.execute_reply.started":"2024-09-29T18:30:47.198649Z"},"trusted":true,"id":"f_bdiCoPD239"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import json\n","import re\n","import os\n","import av\n","import gc\n","from tqdm.notebook import tqdm\n","from PIL import Image\n","from huggingface_hub import hf_hub_download\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n","\n","import torch\n","from transformers import AutoTokenizer, AutoProcessor, LlavaOnevisionForConditionalGeneration, Qwen2VLForConditionalGeneration"]},{"cell_type":"markdown","metadata":{"id":"a8d1xj1FD23-"},"source":["## Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"dRun4Q8GD23_"},"outputs":[],"source":["model = LlavaOnevisionForConditionalGeneration.from_pretrained(\"llava-hf/llava-onevision-qwen2-7b-ov-hf\", torch_dtype=torch.float16, device_map=\"auto\")\n","processor = AutoProcessor.from_pretrained(\"llava-hf/llava-onevision-qwen2-7b-ov-hf\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"xRK7rd7yD24A"},"outputs":[],"source":["def read_frames_from_folder(folder_path, indices):\n","    '''\n","    Reads frames from a folder.\n","    Args:\n","        folder_path (str): Path to the folder containing frames.\n","        indices (List[int]): List of frame indices to decode.\n","    Returns:\n","        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n","    '''\n","    frames = []\n","    # List all files in the folder and sort them to maintain the correct order\n","    frame_files = sorted(os.listdir(folder_path))\n","\n","    # Filter the files based on the provided indices\n","    for i, frame_file in enumerate(frame_files):\n","        if i > indices[-1]:\n","            break\n","        if i in indices:\n","            frame_path = os.path.join(folder_path, frame_file)\n","            frame = Image.open(frame_path)\n","            frames.append(np.array(frame.convert('RGB')))\n","\n","    return np.stack(frames)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"93h4gEVPD24A"},"outputs":[],"source":["video_folder = '/kaggle/input/dota-100/frames_100/accident/0qfbmt4G8Rw_003068/images'\n","total_frames_folder = len(os.listdir(video_folder))\n","\n","# Select indices (example: 8 evenly spaced frames)\n","indices_folder = np.arange(0, total_frames_folder, total_frames_folder / 8).astype(int)\n","video1 = read_frames_from_folder(video_folder, indices_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"ygYuWKm5D24A"},"outputs":[],"source":["conversation1 = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": [\n","            {\"type\": \"video\"},\n","            {\"type\": \"text\", \"text\": \"\"\"\n","                Generate a detailed report in JSON format on the traffic statistics in this video:\n","                {\n","                    vehicles: {\n","                        'car': <count>,\n","                        'truck': <count>,\n","                        'bike': <count>,\n","                        'bicycle': <count>\n","                    },\n","                    congestion_level: '<low|medium|high>',\n","                    accident: '<yes|no>',\n","                    user_query_response: '<Yes|No>, the video contains a person wearing a red-colored t-shirt?'\n","                }\n","            \"\"\"},\n","        ],\n","    },\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"0ZGPjWxGD24B"},"outputs":[],"source":["prompt1 = processor.apply_chat_template(conversation1, add_generation_prompt=True)\n","inputs1 = processor(videos=list(video1), text=prompt1, return_tensors=\"pt\").to(\"cuda:0\", torch.float16)\n","\n","out1 = model.generate(**inputs1, max_new_tokens=120)\n","decoded_output = processor.batch_decode(out1, skip_special_tokens=True, clean_up_tokenization_spaces=True)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"FZp_S_MhD24B"},"outputs":[],"source":["decoded_output[decoded_output.find('json') + 4:].replace('\\n', '').replace(' ', '').replace(\"'\", '\"').replace(\"`\", \"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"LUEAqCm4D24B"},"outputs":[],"source":["# Clean the decoded output to extract only the JSON part.\n","json_data = json.loads(decoded_output[decoded_output.find('json') + 4:].replace('\\n', '').replace(' ', '').replace(\"'\", '\"').replace(\"`\", \"\"))\n","print(json.dumps(json_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"ajISPDDRD24C"},"outputs":[],"source":["data_to_save = {video_folder: json_data}\n","output_file = 'video_data.json'\n","with open(output_file, 'w') as f:\n","    json.dump(data_to_save, f, indent=4)"]},{"cell_type":"markdown","metadata":{"id":"JjHsXYgWD24C"},"source":["## Looping through all the videos"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:31:15.947555Z","iopub.status.busy":"2024-09-29T18:31:15.946779Z","iopub.status.idle":"2024-09-29T18:31:15.954887Z","shell.execute_reply":"2024-09-29T18:31:15.953745Z","shell.execute_reply.started":"2024-09-29T18:31:15.947497Z"},"trusted":true,"id":"0f-mZztOD24C"},"outputs":[],"source":["def read_frames_from_folder(folder_path, indices):\n","    '''\n","    Reads frames from a folder.\n","    Args:\n","        folder_path (str): Path to the folder containing frames.\n","        indices (List[int]): List of frame indices to decode.\n","    Returns:\n","        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n","    '''\n","    frames = []\n","    # List all files in the folder and sort them to maintain the correct order\n","    frame_files = sorted(os.listdir(folder_path))\n","\n","    # Filter the files based on the provided indices\n","    for i, frame_file in enumerate(frame_files):\n","        if i > indices[-1]:\n","            break\n","        if i in indices:\n","            frame_path = os.path.join(folder_path, frame_file)\n","            frame = Image.open(frame_path)\n","            frames.append(np.array(frame.convert('RGB')))\n","\n","    return np.stack(frames)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:31:15.959116Z","iopub.status.busy":"2024-09-29T18:31:15.958762Z","iopub.status.idle":"2024-09-29T18:31:15.971004Z","shell.execute_reply":"2024-09-29T18:31:15.970011Z","shell.execute_reply.started":"2024-09-29T18:31:15.959085Z"},"trusted":true,"id":"9mDaD0uvD24C"},"outputs":[],"source":["base_dir = '../data/test/'\n","\n","def infer(video_folder, video_name):\n","    video_full_path = os.path.join(base_dir, video_folder, video_name)\n","    if video_folder == 'accident':\n","        video_full_path = os.path.join(base_dir, video_folder, video_name, 'images')\n","    total_frames = len(os.listdir(video_full_path))\n","\n","    # Select indices (8 evenly spaced frames)\n","    indices = np.arange(0, total_frames, total_frames / 8).astype(int)\n","    video = read_frames_from_folder(video_full_path, indices)\n","\n","    inputs = processor(videos=list(video), text=prompt, return_tensors=\"pt\").to(\"cuda:0\", torch.float16)\n","\n","    out = model.generate(**inputs, max_new_tokens=120)\n","    decoded_output = processor.batch_decode(out, skip_special_tokens=True, clean_up_tokenization_spaces=True)[0]\n","\n","    json_data = json.loads(decoded_output[decoded_output.find('json') + 4:].replace('\\n', '').replace(' ', '').replace(\"'\", '\"').replace(\"`\", \"\"))\n","\n","#     data_to_save = {video_name: json_data}\n","    output_dir = './responses'\n","    os.makedirs(output_dir, exist_ok=True)\n","    output_file = os.path.join(output_dir, f'{video_name}.json')\n","    with open(output_file, 'w') as f:\n","        json.dump(json_data, f, indent=4)\n","\n","    if json_data[\"accident\"].lower() == \"yes\":\n","        return 1\n","    return 0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:31:15.973000Z","iopub.status.busy":"2024-09-29T18:31:15.972383Z","iopub.status.idle":"2024-09-29T18:31:15.986165Z","shell.execute_reply":"2024-09-29T18:31:15.985327Z","shell.execute_reply.started":"2024-09-29T18:31:15.972957Z"},"trusted":true,"id":"NoFO-AAyD24D"},"outputs":[],"source":["def evalVideos():\n","    video_folders = {'accident': 1, 'non_accident': 0}\n","    true_labels = []\n","    predicted_labels = []\n","\n","    for folder, actual_label in video_folders.items():\n","        video_folder_path = os.path.join(base_dir, folder)\n","        videos = os.listdir(video_folder_path)[:20]\n","        for video_name in tqdm(videos, desc=f'Processing {folder} Videos'):\n","\n","            # Infer the predicted label for the video\n","            predicted_label = infer(folder, video_name)\n","\n","            # Append the actual and predicted labels for evaluation\n","            true_labels.append(actual_label)\n","            predicted_labels.append(predicted_label)\n","\n","            torch.cuda.empty_cache()\n","            gc.collect()\n","\n","    # Calculate evaluation metrics\n","    accuracy = accuracy_score(true_labels, predicted_labels)\n","    f1 = f1_score(true_labels, predicted_labels, average='binary')\n","    precision = precision_score(true_labels, predicted_labels, average='binary')\n","    recall = recall_score(true_labels, predicted_labels, average='binary')\n","\n","    # Print and return the metrics\n","    print(f\"Accuracy: {accuracy}\")\n","    print(f\"F1 Score: {f1}\")\n","    print(f\"Precision: {precision}\")\n","    print(f\"Recall: {recall}\")\n","\n","    return accuracy, f1, precision, recall"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:31:15.987586Z","iopub.status.busy":"2024-09-29T18:31:15.987263Z","iopub.status.idle":"2024-09-29T18:43:10.329126Z","shell.execute_reply":"2024-09-29T18:43:10.328159Z","shell.execute_reply.started":"2024-09-29T18:31:15.987555Z"},"trusted":true,"id":"oFTO2njYD24D","outputId":"a9512c61-e6ea-4d55-ff48-23f947cf9fb7","colab":{"referenced_widgets":["b36bafc134db424a8fb39b2f0c0dd25e"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b36bafc134db424a8fb39b2f0c0dd25e","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model = LlavaOnevisionForConditionalGeneration.from_pretrained(\"llava-hf/llava-onevision-qwen2-7b-ov-hf\", torch_dtype=torch.float16, device_map=\"auto\")\n","processor = AutoProcessor.from_pretrained(\"llava-hf/llava-onevision-qwen2-7b-ov-hf\")\n","\n","conversation = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": [\n","            {\"type\": \"video\"},\n","            {\"type\": \"text\", \"text\": \"\"\"\n","                Generate a detailed report in JSON format on the traffic statistics in this video:\n","                {\n","                    vehicles: {\n","                        'car': <count>,\n","                        'truck': <count>,\n","                        'bike': <count>,\n","                        'bicycle': <count>\n","                    },\n","                    accident: '<yes|no>',\n","                    user_query_response: '<Yes|No>, the video contains a person wearing a red-colored t-shirt?'\n","                }\n","            \"\"\"},\n","        ],\n","    },\n","]\n","\n","prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:43:10.330667Z","iopub.status.busy":"2024-09-29T18:43:10.330360Z","iopub.status.idle":"2024-09-29T19:17:44.500510Z","shell.execute_reply":"2024-09-29T19:17:44.499581Z","shell.execute_reply.started":"2024-09-29T18:43:10.330634Z"},"trusted":true,"id":"DY6SYxktD24E","outputId":"3fcc208a-7ba8-4425-972c-05dd50755e28","colab":{"referenced_widgets":["73bac1905cfc4b94b3e18e805d5d4512","f8a20ff66d7948c086e80bebc9907777"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73bac1905cfc4b94b3e18e805d5d4512","version_major":2,"version_minor":0},"text/plain":["Processing accident Videos:   0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8a20ff66d7948c086e80bebc9907777","version_major":2,"version_minor":0},"text/plain":["Processing non_accident Videos:   0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy: 0.65\n","F1 Score: 0.46153846153846156\n","Precision: 1.0\n","Recall: 0.3\n"]},{"data":{"text/plain":["(0.65, np.float64(0.46153846153846156), np.float64(1.0), np.float64(0.3))"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["evalVideos()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T19:17:44.502480Z","iopub.status.busy":"2024-09-29T19:17:44.501747Z","iopub.status.idle":"2024-09-29T19:17:45.700777Z","shell.execute_reply":"2024-09-29T19:17:45.699755Z","shell.execute_reply.started":"2024-09-29T19:17:44.502446Z"},"trusted":true,"id":"bC0x3MoGD24E"},"outputs":[],"source":["!zip -r responses.zip /kaggle/working/responses"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T19:17:45.702642Z","iopub.status.busy":"2024-09-29T19:17:45.702330Z","iopub.status.idle":"2024-09-29T19:17:48.923960Z","shell.execute_reply":"2024-09-29T19:17:48.922808Z","shell.execute_reply.started":"2024-09-29T19:17:45.702607Z"},"trusted":true,"id":"7_nd91F8D24E"},"outputs":[],"source":["!pip freeze > requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x1wCdV2DD24E"},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5788253,"sourceId":9510599,"sourceType":"datasetVersion"}],"dockerImageVersionId":30776,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"unsloth","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}